---
title: "NYC OpenData - NYC 311 Phone Call Information"
author: "Wencong Li (liwencong1995@gmail.com)"
date: "06/06/2016"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Using etl to connect to a MySQL database & Using NYC311 data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include=FALSE, message=FALSE}
library(knitr)
opts_chunk$set(fig.width = 6, fig.height = 4)
```


## NYC 311 Open Data 

The `nyc311` package provides a interface for urser who are not experts of SQL to create and maintain an SQL database of NYC 311 Phone Call information from NYC OpenData <https://nycopendata.socrata.com>. For `nyc311` package ursers, a reliable data storage directory is all they need . 

## Get started:
### Install packages
The `etl` package provides the generic framework for the `nyc311` package. To install the `nyc311` package, you must install etl first. Since the `nyc311`  packages currently live on GitHub and not on CRAN, you have to install it manually.

```{r, eval=FALSE, message=FALSE}
install.packages("devtools", repos="http://cran.rstudio.com/")
devtools::install_github("beanumber/nyc311")
```

### Load the package
This command loads both `etl` and `dplyr`.
```{r, message=FALSE}
library(nyc311)
```

### Database
The `etl` function has three variables -- `object`, `dir`, and `db`.

`object` is the etl object that you want to create. 

`dir` is a local directory to store files. If you don't specify one, a temporary directory will be created for you.

`db` is a connection to an SQL database. If you don't specify one, a SQLite database will be created for you in dir. MySQL or PostgreSQL database can also be created, but these require external configurations that can be hard to understand for people who are not familiar with SQL. 

## Examples
### Create an etl Object:
```{r}
calls <- etl("nyc311", dir)
```
A SQLite database is created in the `dir` that you specified. 

### Populate the database:
```{r, message=FALSE}
calls %>%
  etl_extract(years = 2010:2011, months = 1:2, n = 100) %>%
  etl_transform(years = 2010:2011, months = 1:2) %>%
  etl_load(years = 2010:2011, months = 1:2)
```
The SQLite database that has just been created is populated with 100 readings from Janarary, 2010 NYC 311 data.

Now you can pull the data that you are interested in into R Environment.
```{r, message=FALSE}
calls <- calls %>%
  tbl("calls") %>%
  collect()
```

And take a look at it.
```{r, message=FALSE}
glimpse(calls)
```
Since all of the `Date` variables have been converted into `char` variables, it would be helpful to transform the data types.

### Transform data types:
```{r, message=FALSE}
library(lubridate)
calls_cleaned <- calls %>%
  mutate(closed_date = ymd_hms(closed_date)) %>%
  mutate(created_date = ymd_hms(created_date)) %>%
  mutate(resolution_action_updated_date =
           ymd_hms(resolution_action_updated_date))
```

Now, take a look at it again.
```{r, message=FALSE}
glimpse(calls_cleaned)
```

### How long does it take for NYC agencies to solve an issue?
People might be interested in the number of days it takes for NYC agencies to solve each case. We can get it by substracting `closed_date` from `created_date`.
```{r}
calls_new <- calls_cleaned %>%
  mutate(difference = as.numeric(closed_date-created_date))%>%
  arrange(difference)
```
Here, we get the number of seconds it takes to resolve each case under a colunmn called `difference`.

Let's take a look at the first 5 rows of `calls_new`. 
```{r}
calls_new %>%
  select(created_date, closed_date, difference) %>%
  head(5)
```
As you can see, some of the `difference` cells have negative entries. Since a case must be created before it is closed, some of the NYC agencies must have made some mistakes in the process of tracking and recording Phone Call information.

Therefore, we probably want to filter out the readings that have negative `difference` values. Then, I can the average number of days by dividing the average number of seconds by `24*60*60` seconds.
```{r}
calls_new <- calls_new %>%
  filter(difference >= 0)
difference <- as.numeric(calls_new$difference)
mean_secs <-mean(difference)
mean_secs
mean_hrs <- mean_secs/(60*60*24) 
mean_hrs
```
It takes the agencies approximately 12 hours and 30 minutes to solve and close an issue.

### How long does it take for different NYC agencies to solve an issue?
One thing that interests me is to see the difference in average number of hours it takes to solve an issue among multiple NYC departments.
```{r}
agency_diff <- calls_new %>%
  group_by(agency_name) %>%
  summarise(number_hrs = mean(difference)/(60*60*24)) %>%
  arrange(number_hrs) 
agency_diff %>%
  head(3)
```
It seems that `New York City Police Department` is doing a great job on quickly solving problems. It take the policemen on average less than 10 minutes to solve each issue.

### How long does it take for NYC agencies to solve differnt types of issue?
Another thing that interests me is the difference in average number of hours it takes to solve each type of complaint. 
```{r}
complaint_diff <- calls_new %>%
  group_by(complaint_type) %>%
  summarise(number_hrs = mean(difference)/(60*60*24)) %>%
  arrange(number_hrs) 
complaint_diff %>%
  head(3)
```
As you can see from the list above, `Illegal Parking` takes the least time to resolve!

### Where did `General Construction` issues occur in NYC?
```{r}
complaint_type <- calls_new %>%
  group_by(complaint_type) %>%
  summarise(N=n()) %>%
  arrange(desc(N)) 

general_construction_location <- calls %>%
  filter(complaint_type == "GENERAL CONSTRUCTION") %>%
  select(latitude, longitude)
```

```{r}
if (require(leaflet)) { 
  leaflet(data = general_construction_location) %>% 
    addTiles() %>%
    addCircles()
}
```

